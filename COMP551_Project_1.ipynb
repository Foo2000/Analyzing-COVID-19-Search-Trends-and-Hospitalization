{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/j-chenn/COMP551_Project_1/blob/main/COMP551_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8j0hsOoM03e"
   },
   "source": [
    "# Task 1: Acquire, pre-process and analyze the data\n",
    "## Acquiring both datasets:\n",
    "Dataset 1: [Search Trends](https://github.com/google-research/open-covid-19-data/blob/master/data/exports/search_trends_symptoms_dataset/README.mdhttps://)\n",
    "\n",
    "Dataset 2: [COVID hospitalization cases](https://github.com/google-research/open-covid-19-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eW-miWaPR0Yt"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import math\n",
    "import statistics\n",
    "from numpy import nanmedian, NaN\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Dza6al16Mj74"
   },
   "outputs": [],
   "source": [
    "# the week of 08/24/2020 for the data collection\n",
    "# Load into pandas dataframes\n",
    "st_df = pd.read_csv('2020_US_weekly_symptoms_dataset.csv', low_memory=False)\n",
    "hp_df = pd.read_csv('aggregated_cc_by.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elRSVGYhZi7L"
   },
   "source": [
    "## Preprocess the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Weeks range: 2020-03-09 to 2020-09-21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JZ2ApGzrZgcZ"
   },
   "outputs": [],
   "source": [
    "# Search trends dataset Part I\n",
    "\n",
    "#TODO: Preprocessing, remove all symptoms that have all zero entries (clean COLUMN)\n",
    "st_df = st_df.dropna(how='all', axis=1)\n",
    "\n",
    "#Remove all rows not in the date of the week chosen (clean ROW)\n",
    "st_df = st_df[st_df['date'] >= '2020-03-04']\n",
    "\n",
    "nameList = list(st_df['sub_region_1']) #extract the region names from st_df database\n",
    "nameList = list(dict.fromkeys(nameList))  #remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospitalization dataset Part I\n",
    "\n",
    "#TODO: Preprocessing\n",
    "\n",
    "#keep the hospitalization features and delete the rest  (clean COLUMN)\n",
    "hp_df = hp_df[['open_covid_region_code','region_name','date', 'hospitalized_new']]\n",
    "\n",
    "#select the regions that match the Search trends dataset (clean ROW)\n",
    "hp_df= hp_df[hp_df.region_name.isin(nameList)]\n",
    "\n",
    "#select the regions that have the valid date range (clean ROW)\n",
    "hp_df = hp_df[(hp_df['date'] >= '2020-03-09') & (hp_df['date'] <= '2020-09-27')]\n",
    "\n",
    "hp_df.reset_index(inplace = True) \n",
    "#print(hp_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospitalization dataset Part II\n",
    "# Here we want to group dates in the same week together as one date (the weekdate)\n",
    "hp_df1 = hp_df\n",
    "weekdate = '2020-03-09'\n",
    "\n",
    "#This loop will update all the dates row by row\n",
    "for i, n in hp_df1.iterrows():\n",
    "    if (i%7 == 0):\n",
    "        weekdate = n['date']  #first date of the week\n",
    "    else:\n",
    "        hp_df1.at[i,'date'] = weekdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region_name        date  hospitalized_new  index open_covid_region_code\n",
      "3          Hawaii  2020-03-09             802.0  87097                  US-HI\n",
      "4           Idaho  2020-03-09            1811.0  86678                  US-ID\n",
      "5           Maine  2020-03-09             445.0  84953                  US-ME\n",
      "6         Montana  2020-03-09             687.0  83701                  US-MT\n",
      "7        Nebraska  2020-03-09            2279.0  83071                  US-NE\n",
      "8   New Hampshire  2020-03-09             736.0  82860                  US-NH\n",
      "9      New Mexico  2020-03-09            3435.0  82413                  US-NM\n",
      "10   North Dakota  2020-03-09             815.0  83280                  US-ND\n",
      "11   Rhode Island  2020-03-09            2725.0  80738                  US-RI\n",
      "12   South Dakota  2020-03-09            1473.0  80311                  US-SD\n",
      "15        Wyoming  2020-03-09             262.0  78166                  US-WY\n"
     ]
    }
   ],
   "source": [
    "#sum up the hospitalized_vew for weekly\n",
    "# we are only using this hp_df2 to rid regions that have insignificant hospitalized data, such as 0 for total hospitalization\n",
    "def cleanRegions(df):\n",
    "    hp_df2 = df\n",
    "    f = dict.fromkeys(hp_df2.columns.difference(['region_name']), 'first')\n",
    "    f['hospitalized_new'] = sum\n",
    "    hp_df2 = hp_df2.groupby('region_name', as_index=False).agg(f)\n",
    "    hp_df2 = hp_df2[hp_df2.hospitalized_new != 0]\n",
    "    print(hp_df2.to_string())\n",
    "    tmplist = list(hp_df2['region_name']) \n",
    "    tmplist = list(dict.fromkeys(tmplist))  \n",
    "    return(tmplist)\n",
    "\n",
    "#this nameList will be a new regions list that removes region with total of 0 hospitalization value for all its dates\n",
    "nameList2 = cleanRegions(hp_df1)\n",
    "\n",
    "#filter hp_df1 based on the nameList2 (clean ROW)\n",
    "hp_df2= hp_df1[hp_df1.region_name.isin(nameList2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospitalization dataset Part III\n",
    "\n",
    "# merge 7 week rows into 1 and sum up the hospitalized_new data\n",
    "hp_df3 = hp_df2.groupby(['region_name','date'])['hospitalized_new'].apply(sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search trends dataset Part II\n",
    "\n",
    "# Drop unnecessary columns (open_covid region_code, country_region_code, country_region) (clean COLUMN)\n",
    "st_df1 = st_df.drop(st_df.columns[[0, 1, 2]], axis=1)\n",
    "\n",
    "# Filter st_df based on nameList2 (clean ROW)\n",
    "st_df1= st_df1[st_df.sub_region_1.isin(nameList2)]\n",
    "# print(st_df1)\n",
    "# print(st_df1.shape)\n",
    "\n",
    "#Filter columns so that every column have at least sp_num% of non-zero entries  (clean COLUMN)\n",
    "sp_num = 0.24  #optimized ratio without tremendous loss of dataset\n",
    "st_df2 = st_df1.dropna(thresh=sp_num*len(st_df), axis=1)\n",
    "\n",
    "\n",
    "st_df2.reset_index(inplace = True) \n",
    "st_df2 = st_df2.drop(st_df2.columns[[0]], axis=1)\n",
    "\n",
    "# print(\"after.........\" )\n",
    "#print(st_df2.head(50))\n",
    "#print(st_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of the Search Trend Datasets:\n",
    "\n",
    "#Find each symptom's median\n",
    "#61 symptoms\n",
    "medianList = []\n",
    "for (columnName, columnData) in st_df2.iteritems(): \n",
    "    if (columnName != 'sub_region_1' and columnName != 'sub_region_1_code' and columnName != 'date'):\n",
    "        m =  nanmedian(columnData.values) \n",
    "#         print(\"my median is\", m)\n",
    "        s = columnData.size\n",
    "        i = 0\n",
    "        for i in range(s):\n",
    "            v = columnData.values[i]\n",
    "            if (math.isnan(v)):\n",
    "                columnData.values[i] = columnData.values[i]\n",
    "            else:\n",
    "#                 print(\"my val before:\", columnData.values[i])\n",
    "                columnData.values[i] = columnData.values[i]/m\n",
    "#                 print(\"my val after:\", columnData.values[i])\n",
    "            i = i+1\n",
    "\n",
    "# print(st_df2.shape)\n",
    "# print(st_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sub_region_1 sub_region_1_code        date  symptom:Adrenal crisis  \\\n",
      "0         Hawaii             US-HI  2020-03-09                     NaN   \n",
      "1         Hawaii             US-HI  2020-03-16                     NaN   \n",
      "2         Hawaii             US-HI  2020-03-23                     NaN   \n",
      "3         Hawaii             US-HI  2020-03-30                     NaN   \n",
      "4         Hawaii             US-HI  2020-04-06                     NaN   \n",
      "..           ...               ...         ...                     ...   \n",
      "314      Wyoming             US-WY  2020-08-24                0.448731   \n",
      "315      Wyoming             US-WY  2020-08-31                0.510660   \n",
      "316      Wyoming             US-WY  2020-09-07                0.341117   \n",
      "317      Wyoming             US-WY  2020-09-14                0.421320   \n",
      "318      Wyoming             US-WY  2020-09-21                0.572589   \n",
      "\n",
      "     symptom:Allergic conjunctivitis  symptom:Angular cheilitis  \\\n",
      "0                                NaN                   2.638177   \n",
      "1                                NaN                   2.334554   \n",
      "2                                NaN                   2.573871   \n",
      "3                                NaN                   3.206349   \n",
      "4                                NaN                   2.951567   \n",
      "..                               ...                        ...   \n",
      "314                         0.383408                        NaN   \n",
      "315                              NaN                        NaN   \n",
      "316                         0.246637                   0.183150   \n",
      "317                              NaN                        NaN   \n",
      "318                              NaN                        NaN   \n",
      "\n",
      "     symptom:Aphonia  symptom:Asphyxia  symptom:Atheroma  \\\n",
      "0           4.708425               NaN               NaN   \n",
      "1           3.682051               NaN               NaN   \n",
      "2           2.664469               NaN               NaN   \n",
      "3           2.084249               NaN               NaN   \n",
      "4           1.690110               NaN               NaN   \n",
      "..               ...               ...               ...   \n",
      "314              NaN          0.356295          0.315733   \n",
      "315              NaN          0.482660          0.372845   \n",
      "316              NaN          0.381948               NaN   \n",
      "317              NaN          0.383848          0.399784   \n",
      "318              NaN          0.275534          0.595905   \n",
      "\n",
      "     symptom:Auditory hallucination  ...  symptom:Rumination  \\\n",
      "0                               NaN  ...                 NaN   \n",
      "1                               NaN  ...                 NaN   \n",
      "2                               NaN  ...                 NaN   \n",
      "3                               NaN  ...                 NaN   \n",
      "4                               NaN  ...                 NaN   \n",
      "..                              ...  ...                 ...   \n",
      "314                        0.539286  ...                 NaN   \n",
      "315                             NaN  ...            0.317903   \n",
      "316                        0.288095  ...            0.319018   \n",
      "317                        0.429762  ...            0.432794   \n",
      "318                        0.326190  ...            0.249861   \n",
      "\n",
      "     symptom:Shallow breathing  symptom:Stridor  symptom:Subdural hematoma  \\\n",
      "0                     4.194585              NaN                        NaN   \n",
      "1                     7.087140              NaN                        NaN   \n",
      "2                     6.249577              NaN                        NaN   \n",
      "3                     5.092217              NaN                        NaN   \n",
      "4                     3.764805              NaN                        NaN   \n",
      "..                         ...              ...                        ...   \n",
      "314                        NaN              NaN                   0.284561   \n",
      "315                   0.245347              NaN                   0.287588   \n",
      "316                   0.186125         0.274033                   0.527750   \n",
      "317                        NaN         0.283978                   0.324924   \n",
      "318                        NaN         0.302762                   0.435923   \n",
      "\n",
      "     symptom:Tenderness  symptom:Trichoptilosis  symptom:Urinary urgency  \\\n",
      "0                   NaN                     NaN                      NaN   \n",
      "1                   NaN                     NaN                      NaN   \n",
      "2                   NaN                     NaN                      NaN   \n",
      "3                   NaN                     NaN                      NaN   \n",
      "4                   NaN                     NaN                      NaN   \n",
      "..                  ...                     ...                      ...   \n",
      "314            0.393281                0.258877                      NaN   \n",
      "315            0.303360                0.294387                      NaN   \n",
      "316            0.423913                     NaN                      NaN   \n",
      "317            0.388340                0.350515                 0.273191   \n",
      "318            0.324111                0.363116                      NaN   \n",
      "\n",
      "     symptom:Ventricular fibrillation  symptom:Viral pneumonia  \\\n",
      "0                                 NaN                 7.843137   \n",
      "1                                 NaN                 6.949020   \n",
      "2                                 NaN                 5.530196   \n",
      "3                                 NaN                 3.669020   \n",
      "4                                 NaN                 2.240784   \n",
      "..                                ...                      ...   \n",
      "314                          0.242780                      NaN   \n",
      "315                               NaN                      NaN   \n",
      "316                               NaN                      NaN   \n",
      "317                               NaN                      NaN   \n",
      "318                          0.316202                      NaN   \n",
      "\n",
      "     hospitalized_new  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                12.0  \n",
      "3                 7.0  \n",
      "4                25.0  \n",
      "..                ...  \n",
      "314               8.0  \n",
      "315               4.0  \n",
      "316               9.0  \n",
      "317              15.0  \n",
      "318              19.0  \n",
      "\n",
      "[319 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "hpData = hp_df3[\"hospitalized_new\"]\n",
    "hpData = pd.Series(hpData)\n",
    "\n",
    "st_df2['hospitalized_new'] = hpData.values # Merging the data_set\n",
    "print(st_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert merged dataset into a numpy array\n",
    "myarray = pd.DataFrame(st_df2).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Task 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0fg+0w8Z9nRsJs3Ucih0p",
   "include_colab_link": true,
   "name": "COMP551_Project_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
